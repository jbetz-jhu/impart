---
title: "Designing Information Monitored Trials for Time-to-Event Outcomes"
description: >
  How to design an information monitored randomized trial for time-to-event outcomes
output: rmarkdown::html_vignette
bibliography:
  - "../inst/covariate_adjustment.bib"
vignette: >
  %\VignetteIndexEntry{Designing Information Monitored Trials for Time-to-Event Outcomes}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
  %\VignetteDepends{pwr}
---

```{r RMD-Setup, include = FALSE}
fig_w <- 8
fig_h <- 8

knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  echo = TRUE,
  message = TRUE,
  error = TRUE,
  purl = FALSE,
  results = "markup",
  fig.path = "../man/figures/",
  fig.width = fig_w,
  fig.height = fig_h,
  fig.align = "center",
  out.width = "80%",
  dpi = 600
)

options(
  rmarkdown.html_vignette.check_title = FALSE
)

set.seed(9876)
```


```{r Alt-Text, include = FALSE}
one_sided_upper_fig_alt <-
  paste0(
    "A figure showing efficacy and futility stopping boundaries for a group ",
    "sequential design with three analyses using a one-sided test where ",
    "higher values of a test statistic indicate the superiority of treatment ",
    "to control. These analyses are conducted when information reaches 50%, ",
    "75%, and 100% of the target information level. The x-axis has values of ",
    "0.50, 0.75, and 100, indicating the information fraction, and the y-axis ",
    "indicates the non-binding futility boundaries. The efficacy boundaries ",
    "decrease from left to right, with a boundary of 2.54 at an information ",
    "fraction of 0.5, and a boundary of 1.72 at an information fraction of 1. ",
    "The futility boundaries increase from left to right, with a boundary of ",
    "0.11 at an information fraction of 0.5, converging with to a boundary of ",
    "1.72 at information fraction of 1."
  )

one_sided_lower_fig_alt <-
  paste0(
    "A figure showing efficacy and futility stopping boundaries for a group ",
    "sequential design with three analyses using a one-sided test where lower ",
    "values of a test statistic indicate the superiority of treatment to ",
    "control. These analyses are conducted when information reaches 50%, 75%, ",
    "and 100% of the target information level. The x-axis has values of 0.50, ",
    "0.75, and 100, indicating the information fraction, and the y-axis ",
    "indicates the non-binding futility boundaries. The efficacy boundaries ",
    "increase from left to right, with a boundary of -2.54 at an information ",
    "fraction of 0.5, and a boundary of -1.72 at an information fraction of ",
    "1. The futility boundaries decrease from left to right, with a boundary ",
    "of -0.11 at an information fraction of 0.5, converging with to a ",
    "boundary of 1.72 at information fraction of 1."
  )
```


```{r Library}
library(impart) 
```

# Planning The Study

Planning an information-monitored study is similar in many respects to planning a study with a fixed sample size. Investigators must decide on [the target of statistical inference, also known as an estimand](https://covariateadjustment.github.io/estimands.html): for a time-to-event outcome, there are several outcomes that may be of interest, including the survival probability (SP), the restricted mean survival time (RMST), or hazard ratio (HR). Royston and Parmar ([@Royston2011; @Royston2013]) provide an overview of RMST, with further practical considerations provided by Eaton, Therneau, and Le-Rademacher [@Eaton2020].

Once the estimand is chosen, decisions must be made about what constitutes a meaningful effect size on the scale of the estimand. Next, the characteristics of the testing procedure must be specified, including the desired Type I Error Rate ($\alpha$), statistical power ($1 - \beta$), and the direction of alternatives of interest (an $s$-sided test: 1- or 2-sided):

```{r Universal-Study-Design-Parameters}
# Universal Study Design Parameters
minimum_difference_hr <- 0.70 # Effect Size: Hazard Ratio
minimum_difference_log_hr <- log(minimum_difference_hr) 
minimum_difference_sp <- 0.15 # Effect Size: Difference in Survival Probability
minimum_difference_rmst <- 1 # Effect Size: Difference in RMST
alpha <- 0.05 # Type I Error Rate
power <- 0.9 # Statistical Power
test_sides <- 2 # Direction of Alternatives
```

Additionally, if the goal is to assess the difference in survival probability or average time being free of the event (RMST), investigators need to specify a clinically meaningful time interval known as the time horizon ($\tau$).

```{r RMST-and-Survival-Probability-Parameters}
# Study Design Parameters: RMST & Survival Probability
time_horizon <- 5
```

```{r Units-for-Time-Horizon, echo = FALSE}
units_time_horizon <- units_rmst_difference <- "year"

if(abs(time_horizon - 1) > 1e-6){
 units_time_horizon <- paste0(units_time_horizon, "s") 
}

if(abs(minimum_difference_rmst - 1) > 1e-6){
 units_rmst_difference <- paste0(units_rmst_difference, "s") 
}
```


For example:

  - A `r (1 - minimum_difference_hr)*100`% reduction in the hazard (a hazard ratio of `r minimum_difference_hr`, or a log hazard ratio of `r round(x = minimum_difference_log_hr, digits = 3)`)
  - A `r minimum_difference_sp*100`% absolute difference in survival probability at $\tau$ = `r time_horizon` `r units_time_horizon`
  - A difference in RMST of `r minimum_difference_rmst` `r units_rmst_difference` at $\tau$ = `r time_horizon` `r units_time_horizon` (`r 100*minimum_difference_rmst/time_horizon`% increase in expected time being event-free)

The amount of data that must be collected depends on the amount of the information in the accruing data, with the information depending on the patterns of associations between covariates, event times, and censoring times. Such information is not always available when studies are being planned in practice.

Sample size calculations for a continuous or binary outcome require estimates of nuisance parameters, such as the variance of continuous outcomes, or the risk of the outcome in the control arm. Power for the logrank test depends on the number of events observed in both treatment $(D_{1})$ and control $(D_{0})$ arms [@Schoenfeld1983]. Let $D = D_{1} + D_{0}$ denote the total number of events in a trial with an allocation ratio of $r$ participants to treatment for every $1$ participants allocated to control ($r:1$ randomization). The power to detect a hazard ratio of $\theta_{H_{A}}$ with Type I error $\alpha$ with an $s$-sided test after observing $D$ events across both treatment arms is:

$$(1 - \beta) = \Phi\left( log(\theta_{H_{A}}) \sqrt{ \frac{rD}{(1 + r)^2} } - Z_{\alpha/s} \right)$$

Alternatively, to achieve power $(1 - \beta)$ requires observing at least $D$ total events, where:

$$D = \frac{(1 + r)^2}{r}\left(\frac{Z_{\alpha/s} + Z_{\beta}}{log(\theta_{H_{A}})}\right)^{2}$$

Since the number of events observed depends on the distribution of event times and censoring times, investigators must choose a sample size $N = N_{1} + N_{0}$ and minimum follow-up duration so that at least $D$ events are observed across both treatment arms by the end of follow-up. This is known as an *event driven trial*: precision and power depend on the number of events observed, with recruitment and follow-up duration adjusted to reach the specified level of precision.


```{r Calculate-Required-Events-For-Hazard-Ratio}
# Number of Events Required:
required_events <- 
  impart::hr_design(
    hazard_ratio = minimum_difference_hr,
    power = power,
    alpha = alpha,
    test_sides = test_sides
  )

required_events
```


Investigators would need to adjust the duration of follow-up, total sample size, and recruitment rate in order to observe a total of `r ceiling(required_events)` during the study period. Similarly, one can determine the power attained after a certain number of events are observed.


```{r Calculate-Power-For-Hazard-Ratio}
impart::hr_design(
  events = required_events*(0.5), # Lower number of events observed
  hazard_ratio = minimum_difference_hr,
  alpha = alpha,
  test_sides = test_sides
)

impart::hr_design(
  events = required_events, # Lower number of events observed
  hazard_ratio = minimum_difference_hr + 0.10, # Lower reduction in hazard
  alpha = alpha,
  test_sides = test_sides
)
```




## Determining the Target Information Level

The information or precision required to achieve power $(1 - \beta)$ to identify a treatment effect $\delta$ with an $s$-sided test with type I error rate $\alpha$ at the final analysis is given by:

$$\mathcal{I}_{F} = \left(\frac{Z_{\alpha/s} + Z_{\beta}}{\delta}\right)^2 \approx \frac{1}{\left(SE(\hat{\delta})\right)^2} = \frac{1}{Var(\hat{\delta})}$$

Note that $\delta$ may be on different scales, depending on the scale of the estimand of interest. Continuous and binary outcomes dealt with information for a difference in means, while time-to-event outcomes could be assessed on the log hazard ratio, survival probability, or restricted mean survival time scale:

#### Information: Log Hazard Ratio

```{r Information-Log-Hazard-Ratio}
# Determine information required to achieve desired power at fixed error rate
information_single_stage_log_hr <-
  impart::required_information_single_stage(
    # Note: Estimand is on log hazard ratio scale
    delta = minimum_difference_log_hr,
    alpha = alpha,
    power = power
  )

information_single_stage_log_hr
```




#### Information: Survival Probability

```{r Information-Survival-Probability}
# Determine information required to achieve desired power at fixed error rate
information_single_stage_sp <-
  impart::required_information_single_stage(
    # Note: Estimand is on survival probability scale
    delta = minimum_difference_sp,
    alpha = alpha,
    power = power
  )

information_single_stage_sp
```


#### Information: Restricted Mean Survival Time

```{r Information-Restricted-Mean-Survival-Time}
information_single_stage_rmst <-
  impart::required_information_single_stage(
    # Note: Estimand is on restricted mean survival time scale
    delta = minimum_difference_rmst,
    alpha = alpha,
    power = power
  )

information_single_stage_rmst
```


For example, `r 100*power`% power and a Type I Error rate of `r alpha` using a `r test_sides`-sided test would require information exceeding:

  - `r round(x = information_single_stage_log_hr, digits = 2)` to detect a difference in the log hazard ratio of $\delta_{log(HR)}$ = `r round(minimum_difference_log_hr, digits = 2)` (i.e. a hazard ratio of `r minimum_difference_hr`)
  - `r round(x = information_single_stage_sp, digits = 2)` to detect a difference in survival probability of $\delta_{SP}$ = `r round(minimum_difference_sp, digits = 2)` at $\tau$ = `r time_horizon` `r units_time_horizon`
  - `r round(x = information_single_stage_rmst, digits = 2)` to detect a difference in restricted mean survival time $\delta_{RMST}$ = `r round(minimum_difference_rmst, digits = 2)` `r units_rmst_difference` at $\tau$ = `r time_horizon` `r units_time_horizon`


Investigators can collect data until the precision (the reciprocal of the square of the standard error) reaches this level, and their analysis will have the appropriate power and Type I error control. This is known as a single stage design, since data are only analyzed at a single point during the study.

For a binary outcome, there's only one nuisance parameter related to the outcome distribution: the risk of the outcome in controls. For a continuous outcome, there are two nuisance parameters: the variance of the outcome in each treatment arm. Unfortunately, with time-to-event outcomes, the number of events $D$ depends on the distribution of both event times and censoring in each arm. For survival probability and RMST, the number of events depends on the time after randomization at which they are evaluated: the time horizon $\tau$.

## Sequential Analyses in Studies

If the true effect of interest is greater than the minimum meaningful effect $\delta$, the study may still be overpowered. Conversely, if the true effect is very small, or indicates that the benefits of participating in the study are not commensurate with risks, it may be futile to continue data collection. In such cases, interim analyses of the data can be used to guide more ethical, cost-effective data collection. These are known as multi-stage designs, as data are analyzed at multiple points in the study.

Group-Sequential Designs allow investigators to control Type I Error rates when performing pre-specified interim assessments of the differences between groups. Studies can also be stopped early for futility if accruing data suggest that a treatment is ineffective or harmful. The number and timing of analyses must be pre-specified, as well as the rules for stopping for efficacy and futility. The stopping rules are specified using 'spending functions:' alpha spending functions define efficacy stopping rules, and beta spending functions define futility stopping rules. For more information on group sequential designs, see [the documentation for the `RPACT` package](https://www.rpact.org). This example will utilize the O'Brien-Fleming stopping rules for efficacy and futility.

In contrast to a group sequential design, which performs analyses at pre-specified fractions of the final sample size, an information-monitored study performs analyses when the data collected provide enough precision to identify a treatment effect with the appropriate power and Type I Error. Analyses are conducted when the precision reaches pre-specified fractions of this level of precision.

```{r Group-Sequential-Design-Parameters}
# Group Sequential Design Parameters
information_rates <-
  c(0.50, 1.00) # Analyses at 50% and 100% of the Total Information
type_of_design <- "asOF" # O'Brien-Fleming Alpha Spending
type_beta_spending <- "bsOF" # O'Brien-Fleming Beta Spending
```

The `getDesignGroupSequential` function in the `rpact` library can be used to specify the appropriate study design. For example, a two-sided test comparing  $H_{0}: \mu_{T} - \mu_{C} = \delta_{0}$ vs. $H_{A}: \mu_{T} - \mu_{C} \neq \delta_{0}$

```{r Specify-Two-Sided-Sequential-Design-Procedure}
# Set up group sequential testing procedure
trial_design <-
  rpact::getDesignGroupSequential(
    alpha = alpha,
    beta = 1 - power,
    sided = 2,
    informationRates = information_rates,
    typeOfDesign = type_of_design,
    typeBetaSpending = type_beta_spending,
    bindingFutility = FALSE
  )
```




## Adjusting Information for Multiple Analyses

When doing sequential analyses in an information-monitored design, the target level of information must be adjusted:

```{r Adjust-Information-Target-Using-GSD}
# Inflate information level to account for multiple testing
information_adaptive_log_hr <-
  impart::required_information_sequential(
    information_single_stage = information_single_stage_log_hr,
    trial_design = trial_design
  )

information_adaptive_log_hr
```

The information required under the specified design for the log hazard ratio is `r information_adaptive_log_hr`, which is scaled up by the inflation factor mentioned in the summary of the design (`r rpact::getDesignCharacteristics(trial_design)$inflationFactor`). This can be retrieved using `rpact::getDesignCharacteristics(trial_design)`.



## Including Covariate Information

For the log hazard ratio, if only the number of events $D$ is known, along with the sample size in the treatment ($N_{1}$) and control ($N_{0}$) arms, the variance of the log hazard ratio can be approximated by [@Tierney2025]:

$$var(\theta_{log(HR)}) = (N_{1} +N_{0})^2/(DN_{1}N_{0}) = (1 + r)^2/(rD)$$
The information is approximately: 

$$\mathcal{I}_{log(HR)} = DN_{1}N_{0}/(N_{1} +N_{0})^2 = Dr/(1 + r)^2$$
This approximation is used in `asymptotic_information_logrank` which determines the amount of information from an $r:1$ randomized trial:

```{r Check-Approximation-with-Schoenfeld-Formula}
# Information for 1:1 trial with number of events from Schoenfeld formula
impart::asymptotic_information_logrank(
  allocation_ratio = 1,
  total_events = 
    impart::hr_design(
      hazard_ratio = minimum_difference_hr,
      power = power,
      alpha = alpha,
      test_sides = test_sides,
      ratio = 1
    )
)

# Information target based on delta, alpha, power for single stage design
information_single_stage_log_hr
```

```{r Calculate-Relative-Efficiency}
relative_efficiency <- c(1, 1.1, 1.2)

adjusted_events <-
  information_to_events_log_hr(
    information = information_single_stage_log_hr/relative_efficiency,
    round_up = TRUE
  )

data.frame(
  relative_efficiency = relative_efficiency,
  information_adjusted = information_single_stage_log_hr,
  setNames(
    object = adjusted_events,
    nm = c("information_unadjusted", "allocation_ratio", "total_events")
  )
)
```

This pre-trial planning can help investigators determine when information thresholds may be reached under different potential gains from covariate adjustment when inferring about the marginal hazard ratio.

Power and sample size software exists for design calculations with the RMST, including the [RMSTdesign package](https://github.com/anneae/RMSTdesign/tree/master) [@Eaton2020], and the [SSRMST package](https://cran.r-project.org/web/packages/SSRMST/index.html).

Until the variance of the RMST or survival probability can be approximated by the number of observed events, investigators will have to rely on information monitoring during an ongoing trial.


## References
